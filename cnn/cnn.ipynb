{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    TerminateOnNaN,\n",
    "    ModelCheckpoint,\n",
    "    TensorBoard,\n",
    "    ReduceLROnPlateau\n",
    ")\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_models as tfm\n",
    "import tensorflow_datasets as tfds\n",
    "import sys, math, time\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "import os\n",
    "import logging\n",
    "import shutil\n",
    "from utils import generate_gan_samples, generate_gan_samples1\n",
    "\n",
    "print('Python version:', sys.version)\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('GPU found at: {}'.format(device_name))\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear previous models from memory\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define constants and hyperparameters\n",
    "EPOCHS = 100\n",
    "NUMBER_POLICIES = 5\n",
    "DATASET_NAME = \"cifar10\"\n",
    "NETWORK = \"resnet\"\n",
    "RESIZE_TO = (32,32,3) if NETWORK == \"resnet\" else (75, 75, 3)\n",
    "BATCH_SIZE = 512\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "SEED = 42\n",
    "FOLDER = \".\" + os.sep + DATASET_NAME + os.sep + NETWORK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the old folders generated during training\n",
    "if os.path.exists(FOLDER):\n",
    "    shutil.rmtree(FOLDER)\n",
    "\n",
    "# Creating folders to save images, models and checkpoints\n",
    "newpaths = [FOLDER]\n",
    "for newpath in newpaths:\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_set, valid_set, test_set), info = tfds.load(\n",
    "    \"fashion_mnist\" if DATASET_NAME == \"fmnist\" else DATASET_NAME,\n",
    "    split=[\"train[:90%]\", \"train[90%:]\", \"test\"],\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    "    shuffle_files=True\n",
    ")\n",
    "# Extract informative features\n",
    "class_names = info.features[\"label\"].names\n",
    "num_classes = info.features[\"label\"].num_classes\n",
    "input_shape = info.features['image'].shape\n",
    "IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS = input_shape\n",
    "NUM_TRAIN = len(train_set)\n",
    "print(\"Image shape: {}\".format(input_shape))\n",
    "print(\"Classes: {}\".format(class_names))\n",
    "print(\"Number of classes: {}\".format(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate GAN samples (regular labels from 0 to 9)\n",
    "gan_set = generate_gan_samples(DATASET_NAME, NUM_TRAIN)\n",
    "assert len(gan_set) == NUM_TRAIN, \"GAN samples not generated correctly\"\n",
    "print(\"Generated {} GAN samples\".format(len(gan_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/tensorflow/models/blob/v2.12.0/official/vision/ops/augment.py#L2048-L2194\n",
    "exclude_list = [\"Cutout\"]\n",
    "augmenter = tfm.vision.augment.RandAugment(num_layers=2, magnitude=9,translate_const=4, exclude_ops=exclude_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_rescale(image, label):\n",
    "    # Add RGB channel\n",
    "    image = tf.image.grayscale_to_rgb(image) if IMG_CHANNELS == 1 else image\n",
    "    # Reshape without distortions\n",
    "    image = tf.image.resize_with_pad(image, *RESIZE_TO[:2])\n",
    "    # Convert to float32\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # One-hot encode labels\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    return image, label\n",
    "\n",
    "def prepare_dataset(dataset, shuffle=False, augment=False):\n",
    "    # Resize and rescale the dataset.\n",
    "    dataset = dataset.map(resize_and_rescale, num_parallel_calls=AUTO).cache()\n",
    "    # Shuffle the dataset.\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(len(dataset))\n",
    "    # Batch the dataset.\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # Augment the dataset using RandAugment.\n",
    "    if augment:\n",
    "        dataset = dataset.map(lambda x, y: (augmenter.distort(x), y), num_parallel_calls=AUTO)\n",
    "    # Prefetch the dataset.\n",
    "    return dataset.prefetch(AUTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dataset(dataset, title=\"Dataset samples\"):\n",
    "    plt.figure().suptitle(title, fontsize=14)\n",
    "    for images, labels in dataset.take(1):\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            img = tf.keras.utils.array_to_img(images[i])\n",
    "            plt.imshow(img)\n",
    "            plt.title(class_names[tf.argmax(labels[i])])\n",
    "            plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model building utility function\n",
    "def get_training_model(model_name):\n",
    "    if model_name == \"resnet\":\n",
    "        network = tf.keras.applications.ResNet50V2(\n",
    "            weights=\"imagenet\",\n",
    "            include_top=False,\n",
    "            input_shape=RESIZE_TO,\n",
    "        )\n",
    "    elif model_name == \"inception\":\n",
    "        network = tf.keras.applications.InceptionV3(\n",
    "            weights=\"imagenet\",\n",
    "            include_top=False,\n",
    "            input_shape=RESIZE_TO,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(\"network not supported\")\n",
    "\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Input(RESIZE_TO),\n",
    "            keras.layers.Rescaling(scale=1.0 / 255.0),\n",
    "            network,\n",
    "            keras.layers.GlobalAveragePooling2D(),\n",
    "            keras.layers.Dense(num_classes),\n",
    "        ],\n",
    "        name = model_name,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_ds):\n",
    "    model = get_training_model(NETWORK)\n",
    "    model.load_weights(INITIAL_WEIGHTS)\n",
    "    model.compile(\n",
    "        optimizer=Adam(3e-4),\n",
    "        loss=CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    callbacks = [\n",
    "        TerminateOnNaN(),\n",
    "        ReduceLROnPlateau(factor=1/3.0),\n",
    "        EarlyStopping(patience=40, restore_best_weights=True),\n",
    "        ModelCheckpoint(\n",
    "            filepath=FINAL_WEIGHTS, save_weights_only=True, save_best_only=True\n",
    "        ),\n",
    "    ]\n",
    "    start = time.perf_counter()\n",
    "    history = model.fit(\n",
    "        train_ds, epochs=EPOCHS, validation_data=val_ds, callbacks=callbacks, verbose=1\n",
    "    )\n",
    "    latency = time.perf_counter() - start\n",
    "    return [history, model, latency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, policy):\n",
    "    # plot loss during training\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, sharex=True, figsize=(10, 6))\n",
    "    fig.suptitle(\"Policy {} for {} on {}\".format(policy, DATASET_NAME, NETWORK))\n",
    "    ax1.set_title(\"Training Loss\")\n",
    "    ax1.plot(history.history[\"loss\"], \"--\")\n",
    "    ax1.plot(history.history[\"val_loss\"], \"--\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend([\"training\", \"validation\"], loc=\"best\")\n",
    "    # plot accuracy during training\n",
    "    ax2.set_title(\"Training Accuracy\")\n",
    "    ax2.plot(history.history[\"accuracy\"], \"--\")\n",
    "    ax2.plot(history.history[\"val_accuracy\"], \"--\")\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.legend([\"training\", \"validation\"], loc=\"best\")\n",
    "    # Set the tick locations\n",
    "    #plt.xticks(np.arange(0, EPOCHS +1, 1))\n",
    "    # Save the figure\n",
    "    plt.savefig(FOLDER + \"/{}_{}_policy{}_plot.png\".format(DATASET_NAME, NETWORK, policy))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refactor to plot all policies using one function with proper titles\n",
    "def plot_combined_history(histories,training=True,validation=True):\n",
    "    #epochs = range(1, EPOCHS+1)\n",
    "    if training==True and validation==False:\n",
    "        title = \"Training for all policies\"\n",
    "    elif training==False and validation==True:\n",
    "        title = \"Validation for all policies\" #or another title is Accuracy curves on the validation set for all policies\n",
    "    else:\n",
    "        title = \"Training and Validation for all policies\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, sharex=True, figsize=(10, 6))\n",
    "    fig.suptitle(title)\n",
    "    for i,history in enumerate(histories):\n",
    "        policy = history.history[\"policy\"][0]\n",
    "        label_train = f\"train - policy {policy}\"\n",
    "        label_val = f\"val - policy {policy}\"\n",
    "        ax1.set_title(\"Model Loss\")\n",
    "        ax1.plot(history.history[\"loss\"],label=label_train) if training else None\n",
    "        ax1.plot(history.history[\"val_loss\"],\"--\",label=label_val) if validation else None\n",
    "        #ax1.legend([label_train, label_val], loc=\"best\")\n",
    "        ax1.legend()\n",
    "        ax1.set_xlabel(\"Epochs\")\n",
    "        ax1.set_ylabel(\"Loss\")\n",
    "        #ax1.set_ylim([0, 7.0])\n",
    "        #ax1.set_ylim(0, 4)\n",
    "        # plot accuracy during training\n",
    "        ax2.set_title(\"Model Accuracy\")\n",
    "        ax2.plot(history.history[\"accuracy\"], label=label_train) if training else None\n",
    "        ax2.plot(history.history[\"val_accuracy\"], \"--\",label=label_val) if validation else None\n",
    "        #ax2.legend([label_train, label_val], loc=\"best\")\n",
    "        ax2.legend()\n",
    "        ax2.set_xlabel(\"Epochs\")\n",
    "        ax2.set_ylabel(\"Accuracy\")\n",
    "        #ax2.set_ylim(0, 1)\n",
    "    #plt.xticks(np.arange(0, EPOCHS +1, 10))\n",
    "    plt.savefig(FOLDER + \"/{}_{}_combined_plot.png\".format(DATASET_NAME,NETWORK))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_metrics(model,latency,policy):\n",
    "    # Generate predictions\n",
    "    predictions = model.predict(test_ds, verbose=0)\n",
    "    # Get the predicted labels\n",
    "    predictions = predictions.argmax(axis=1)\n",
    "    # Get the true labels\n",
    "    y_true = np.concatenate([y for _, y in test_ds]).argmax(axis=1)\n",
    "    # Get the classification report\n",
    "    report = classification_report(y_true, predictions, output_dict=True)\n",
    "    print(\"\\n**CLASSIFICATION REPORT**\")\n",
    "    print(pd.DataFrame(report).transpose())\n",
    "    # Get the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true, predictions)\n",
    "    print(\"\\n**CONFUSION MATRIX**\")\n",
    "    print(pd.DataFrame(conf_matrix))\n",
    "    # Get model metrics\n",
    "    metrics = {\n",
    "        \"dataset\": DATASET_NAME,\n",
    "        \"model\": NETWORK,\n",
    "        \"params\": NUMBER_PARAMETERS,\n",
    "        \"policy\": policy,\n",
    "        \"accuracy\": [report[\"accuracy\"]],\n",
    "        \"precision\": [report[\"macro avg\"][\"precision\"]],\n",
    "        \"recall\": [report[\"macro avg\"][\"recall\"]],\n",
    "        \"f1-score\": [report[\"macro avg\"][\"f1-score\"]],\n",
    "        \"training-time(s)\": [latency],\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_metrics(metrics):\n",
    "    file_name = FOLDER + \"/{}_{}_policy_results.csv\".format(DATASET_NAME, NETWORK)\n",
    "    results = []\n",
    "    for i, metric in enumerate(metrics):\n",
    "        # create and store dataframe\n",
    "        df = pd.DataFrame(metric)\n",
    "        results.append(df)\n",
    "    # concatenate all dataframes\n",
    "    results = pd.concat(results)\n",
    "    # save to csv\n",
    "    results.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_train_history(train_history):\n",
    "    file_name = FOLDER + \"/{}_{}_history.csv\".format(DATASET_NAME, NETWORK)\n",
    "    results = []\n",
    "    for i, history in enumerate(train_history):\n",
    "        # create and store dataframe\n",
    "        df = pd.DataFrame(history.history)\n",
    "        results.append(df)\n",
    "    # concatenate all dataframes\n",
    "    results = pd.concat(results)\n",
    "    # save to csv\n",
    "    results.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "val_ds = prepare_dataset(valid_set)\n",
    "# Testing dataset\n",
    "test_ds = prepare_dataset(test_set)\n",
    "# Training dataset (policy 1)\n",
    "train_ds = prepare_dataset(train_set, shuffle=True)\n",
    "# Augmented training dataset (policy 2)\n",
    "train_ds_aug = prepare_dataset(train_set, shuffle=True, augment=True)\n",
    "# GAN dataset (policy 3)\n",
    "gan_ds = prepare_dataset(gan_set, shuffle=True)\n",
    "# GAN plus basic training dataset (policy 4).\n",
    "# Combine the (shuffled) datasets randomly.\n",
    "gan_train_ds = tf.data.Dataset.sample_from_datasets([train_ds, gan_ds], [0.5, 0.5])\n",
    "# Augment GAN dataset (policy 5)\n",
    "gan_ds_aug = prepare_dataset(gan_set, shuffle=True, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset(train_ds, title=\"Basic samples\"),\n",
    "visualize_dataset(train_ds_aug, title=\"Augmented samples\"),\n",
    "visualize_dataset(gan_ds, title=\"GAN samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = get_training_model(NETWORK)\n",
    "NUMBER_PARAMETERS = initial_model.count_params()\n",
    "INITIAL_WEIGHTS = FOLDER + f\"/{DATASET_NAME}_{NETWORK}_initial_weights.h5\"\n",
    "FINAL_WEIGHTS = FOLDER + f\"/{DATASET_NAME}_{NETWORK}_final_weights.h5\"\n",
    "initial_model.summary()\n",
    "# For reproducibility, we first save the initialize weights\n",
    "initial_model.save_weights(INITIAL_WEIGHTS)\n",
    "# Save network structure\n",
    "plot_model(\n",
    "    initial_model,\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    to_file=FOLDER + f\"/{DATASET_NAME}_{NETWORK}_model.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_history = []\n",
    "train_metrics = []\n",
    "# five policies\n",
    "for i in range(2, 3):\n",
    "    if i == 1:\n",
    "        history, model, latency = train_model(train_ds)\n",
    "    elif i == 2:\n",
    "        history, model, latency = train_model(train_ds_aug)\n",
    "    elif i == 3:\n",
    "        history, model, latency = train_model(gan_ds)\n",
    "    elif i == 4:\n",
    "        history, model, latency = train_model(gan_train_ds)\n",
    "    elif i == 5:\n",
    "        history, model, latency = train_model(gan_ds_aug)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Policy does not exist\")\n",
    "    # compute performance metrics\n",
    "    metrics = get_performance_metrics(model, latency, i)\n",
    "    # add policy number to history\n",
    "    history.history[\"policy\"] = [i] * len(history.history[\"loss\"])\n",
    "    # show plot for policy\n",
    "    plot_history(history, i)\n",
    "    # save history and metrics of policy to array\n",
    "    train_history.append(history)\n",
    "    train_metrics.append(metrics)\n",
    "    # save model\n",
    "    model.save(FOLDER + \"/{}_{}_policy{}_model.h5\".format(DATASET_NAME, NETWORK, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss and accuracy for all policies\n",
    "plot_combined_history(train_history)\n",
    "plot_combined_history(train_history, training=False,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save history and metrics to file\n",
    "save_model_metrics(train_metrics)\n",
    "save_train_history(train_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84d8cac4d95fdd2ab02498a6ec40a50cb9882041e67cb52e6d8bcfda00d28db9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
